import os
import cv2
import math
from tqdm import tqdm
import torch
import numpy as np
from facexlib.detection import init_detection_model
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
import threading
import time
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================
INPUT_ROOT = r"E:\00_fjw\00_data\FF++\FaceForensics++_RAW_split"
OUTPUT_ROOT = r"E:\00_fjw\00_data\FF++\FaceForensics++_RAW_split_cropped"

# FaceForensics++ æ•°æ®é›†ç»“æ„
# SPLITS = ["train", "test", "val"]
SPLITS = ["test"]

CATEGORIES = ["Deepfakes", "Face2Face", "FaceShifter", "FaceSwap", "NeuralTextures", "original"]
# CATEGORIES = ["original"]

# äººè„¸è£å‰ªå‚æ•°
PADDING_RATIO = 0.2
FRAME_INTERVAL = 5  # æ¯5å¸§é‡‡æ ·1å¸§
BATCH_SIZE = 32  # æ‰¹é‡å¤„ç†å¸§æ•°
NUM_IO_THREADS = 16  # I/Oçº¿ç¨‹æ•°ï¼ˆä¿å­˜å›¾ç‰‡ï¼‰
NUM_READER_THREADS = 8  # è§†é¢‘è¯»å–çº¿ç¨‹æ•°
GPU_QUEUE_SIZE = 8  # GPUä»»åŠ¡é˜Ÿåˆ—å¤§å°
WRITE_QUEUE_SIZE = 32  # å†™å…¥é˜Ÿåˆ—å¤§å°


# ===========================================


def _ensure_gpu_or_die():
    if not torch.cuda.is_available():
        raise RuntimeError("æœªæ£€æµ‹åˆ° CUDA GPUã€‚è¯·ç¡®è®¤å®‰è£…äº† CUDA ç‰ˆ torchã€‚")


def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)


def get_largest_face(faces):
    """è·å–æœ€å¤§äººè„¸"""
    if not faces:
        return None
    max_area = 0
    best_face_area = None
    for key in faces:
        face = faces[key]
        box = face['facial_area']
        x1, y1, x2, y2 = box
        area = (x2 - x1) * (y2 - y1)
        if area > max_area:
            max_area = area
            best_face_area = box
    return best_face_area


def crop_face_to_square_strict(img, box, padding=0.0):
    """è£å‰ªäººè„¸ä¸ºæ­£æ–¹å½¢"""
    h_img, w_img = img.shape[:2]
    x1, y1, x2, y2 = box

    cx = (x1 + x2) // 2
    cy = (y1 + y2) // 2

    w_face = x2 - x1
    h_face = y2 - y1
    max_side = max(w_face, h_face)

    ideal_side = int(max_side * (1 + padding))
    ideal_radius = ideal_side // 2

    dist_left = cx
    dist_right = w_img - cx
    dist_top = cy
    dist_bottom = h_img - cy

    max_allowed_radius = min(dist_left, dist_right, dist_top, dist_bottom)
    final_radius = min(ideal_radius, max_allowed_radius)

    nx1 = cx - final_radius
    nx2 = cx + final_radius
    ny1 = cy - final_radius
    ny2 = cy + final_radius

    return img[max(0, ny1):min(h_img, ny2), max(0, nx1):min(w_img, nx2)]


def detect_faces_with_retinaface(detector, img_bgr, conf_threshold=0.5):
    """ä½¿ç”¨RetinaFaceæ£€æµ‹äººè„¸"""
    h, w = img_bgr.shape[:2]

    with torch.no_grad():
        try:
            detections = detector.detect_faces(
                img_bgr,
                conf_threshold=conf_threshold,
                use_origin_size=True
            )
        except Exception as e:
            return None

    if detections is None or len(detections) == 0:
        return None

    faces = {}
    for idx, detection in enumerate(detections, 1):
        x1, y1, x2, y2, score = detection[:5]

        if score < conf_threshold:
            continue

        x1 = max(0, min(w, int(x1)))
        y1 = max(0, min(h, int(y1)))
        x2 = max(0, min(w, int(x2)))
        y2 = max(0, min(h, int(y2)))

        if x2 <= x1 or y2 <= y1:
            continue

        faces[f"face_{idx}"] = {
            "score": float(score),
            "facial_area": [x1, y1, x2, y2]
        }

    return faces if faces else None


def detect_faces_batch(detector, frames, conf_threshold=0.5):
    """æ‰¹é‡æ£€æµ‹äººè„¸"""
    results = []
    with torch.no_grad():
        for frame in frames:
            faces = detect_faces_with_retinaface(detector, frame, conf_threshold)
            results.append(faces)
    return results


def video_reader_worker(video_queue, batch_queue, stats):
    """è§†é¢‘è¯»å–å·¥ä½œçº¿ç¨‹"""
    while True:
        task = video_queue.get()
        if task is None:  # ç»“æŸä¿¡å·
            break

        video_path, save_folder = task

        # è¯»å–è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            stats['failed_videos'] += 1
            video_queue.task_done()
            continue

        frames = []
        indices = []
        frame_idx = 0

        # è¿ç»­è¯»å–æ‰€æœ‰å¸§
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_idx % FRAME_INTERVAL == 0:
                frames.append(frame)
                indices.append(frame_idx)

                # è¾¾åˆ°æ‰¹æ¬¡å¤§å°ï¼Œæ”¾å…¥GPUé˜Ÿåˆ—
                if len(frames) >= BATCH_SIZE:
                    batch_queue.put((frames.copy(), indices.copy(), save_folder))
                    stats['batches_queued'] += 1
                    frames = []
                    indices = []

            frame_idx += 1

        # å¤„ç†å‰©ä½™å¸§
        if frames:
            batch_queue.put((frames, indices, save_folder))
            stats['batches_queued'] += 1

        cap.release()
        stats['videos_read'] += 1
        video_queue.task_done()


def gpu_processor_worker(batch_queue, write_queue, detector, stats):
    """GPUå¤„ç†å·¥ä½œçº¿ç¨‹"""
    while True:
        try:
            batch_data = batch_queue.get(timeout=1)
        except queue.Empty:
            continue

        if batch_data is None:  # ç»“æŸä¿¡å·
            break

        frames, indices, save_folder = batch_data

        # GPUæ‰¹é‡æ£€æµ‹
        faces_batch = detect_faces_batch(detector, frames, conf_threshold=0.5)

        # å¤„ç†æ¯ä¸€å¸§
        for frame, faces, frame_idx in zip(frames, faces_batch, indices):
            try:
                if faces and isinstance(faces, dict):
                    box = get_largest_face(faces)
                    if box is not None:
                        face_img = crop_face_to_square_strict(frame, box, padding=PADDING_RATIO)

                        if face_img is not None and face_img.size > 0:
                            save_name = os.path.join(save_folder, f"{frame_idx:05d}.png")
                            write_queue.put((face_img, save_name))
                            stats['faces_detected'] += 1
            except Exception as e:
                pass

        stats['batches_processed'] += 1
        stats['frames_processed'] += len(frames)
        batch_queue.task_done()


def image_writer_worker(write_queue):
    """å›¾ç‰‡ä¿å­˜çº¿ç¨‹"""
    while True:
        item = write_queue.get()
        if item is None:
            break

        face_img, save_path = item
        try:
            cv2.imwrite(save_path, face_img)
        except Exception as e:
            pass

        write_queue.task_done()


def progress_monitor(stats, total_videos, pbar):
    """è¿›åº¦ç›‘æ§çº¿ç¨‹"""
    last_videos = 0

    while stats['videos_read'] + stats['failed_videos'] < total_videos:
        time.sleep(1)

        # æ›´æ–°è¿›åº¦æ¡
        current_videos = stats['videos_read'] + stats['failed_videos']
        videos_delta = current_videos - last_videos
        if videos_delta > 0:
            pbar.update(videos_delta)
            last_videos = current_videos


def collect_video_tasks():
    """æ”¶é›†æ‰€æœ‰è§†é¢‘ä»»åŠ¡"""
    all_tasks = []
    skipped_count = 0  # ç»Ÿè®¡è·³è¿‡çš„è§†é¢‘æ•°

    for split in SPLITS:
        for category in CATEGORIES:
            input_cat_path = os.path.join(INPUT_ROOT, split, category)
            output_cat_path = os.path.join(OUTPUT_ROOT, split, category)

            if not os.path.exists(input_cat_path):
                print(f"âš  è­¦å‘Š: ç›®å½•ä¸å­˜åœ¨ {input_cat_path}ï¼Œè·³è¿‡")
                continue

            video_files = [f for f in os.listdir(input_cat_path) if f.lower().endswith('.mp4')]

            if not video_files:
                print(f"âš  è­¦å‘Š: {input_cat_path} ä¸­æ²¡æœ‰æ‰¾åˆ° .mp4 æ–‡ä»¶")
                continue

            for video_file in video_files:
                video_path = os.path.join(input_cat_path, video_file)
                video_name = os.path.splitext(video_file)[0]
                save_folder = os.path.join(output_cat_path, video_name)

                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ–‡ä»¶
                if os.path.exists(save_folder) and os.listdir(save_folder):
                    skipped_count += 1
                    continue  # è·³è¿‡å·²å¤„ç†çš„è§†é¢‘

                ensure_dir(save_folder)
                all_tasks.append((video_path, save_folder))

            print(f"ğŸ“ {split}/{category}: {len(video_files)} ä¸ªè§†é¢‘ (è·³è¿‡ {skipped_count} ä¸ª)")
            skipped_count = 0  # é‡ç½®è®¡æ•°

    return all_tasks

def process_videos():
    """ä¸»å¤„ç†å‡½æ•°"""
    _ensure_gpu_or_die()

    print("=" * 60)
    print("FaceForensics++ äººè„¸è£å‰ªå·¥å…·")
    print("=" * 60)
    print(f"è¾“å…¥ç›®å½•: {INPUT_ROOT}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_ROOT}")
    print(f"Padding æ¯”ä¾‹: {PADDING_RATIO}")
    print(f"é‡‡æ ·é—´éš”: æ¯ {FRAME_INTERVAL} å¸§å– 1 å¸§")
    print(f"æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
    print(f"è¯»å–çº¿ç¨‹æ•°: {NUM_READER_THREADS}")
    print(f"ä¿å­˜çº¿ç¨‹æ•°: {NUM_IO_THREADS}")
    print(f"GPUé˜Ÿåˆ—å¤§å°: {GPU_QUEUE_SIZE}")
    print("=" * 60)

    print("\næ­£åœ¨åŠ è½½ RetinaFace æ¨¡å‹...")
    detector = init_detection_model('retinaface_resnet50')
    detector.eval()
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = defaultdict(int)

    # åˆ›å»ºä¸‰ä¸ªé˜Ÿåˆ—
    video_queue = queue.Queue(maxsize=NUM_READER_THREADS * 2)
    batch_queue = queue.Queue(maxsize=GPU_QUEUE_SIZE)
    write_queue = queue.Queue(maxsize=WRITE_QUEUE_SIZE)

    # æ”¶é›†æ‰€æœ‰è§†é¢‘ä»»åŠ¡
    print("\næ­£åœ¨æ‰«æè§†é¢‘æ–‡ä»¶...")
    all_video_tasks = collect_video_tasks()
    total_videos = len(all_video_tasks)

    if total_videos == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return

    print(f"\næ€»è®¡: {total_videos} ä¸ªè§†é¢‘å¾…å¤„ç†")
    print("=" * 60)

    # å¯åŠ¨å†™å…¥çº¿ç¨‹æ± 
    print("\nå¯åŠ¨å†™å…¥çº¿ç¨‹...")
    write_threads = []
    for _ in range(NUM_IO_THREADS):
        t = threading.Thread(target=image_writer_worker, args=(write_queue,))
        t.daemon = True
        t.start()
        write_threads.append(t)

    # å¯åŠ¨GPUå¤„ç†çº¿ç¨‹
    print("å¯åŠ¨GPUå¤„ç†çº¿ç¨‹...")
    gpu_thread = threading.Thread(
        target=gpu_processor_worker,
        args=(batch_queue, write_queue, detector, stats)
    )
    gpu_thread.daemon = True
    gpu_thread.start()

    # å¯åŠ¨è§†é¢‘è¯»å–çº¿ç¨‹æ± 
    print("å¯åŠ¨è§†é¢‘è¯»å–çº¿ç¨‹...")
    reader_threads = []
    for _ in range(NUM_READER_THREADS):
        t = threading.Thread(target=video_reader_worker, args=(video_queue, batch_queue, stats))
        t.daemon = True
        t.start()
        reader_threads.append(t)

    print("\nå¼€å§‹å¤„ç†...\n")

    # å¯åŠ¨è¿›åº¦æ¡
    pbar = tqdm(total=total_videos, desc="æ€»è¿›åº¦", unit="video")

    # å¯åŠ¨ç›‘æ§çº¿ç¨‹
    monitor_thread = threading.Thread(target=progress_monitor, args=(stats, total_videos, pbar))
    monitor_thread.daemon = True
    monitor_thread.start()

    # å°†æ‰€æœ‰è§†é¢‘ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
    for task in all_video_tasks:
        video_queue.put(task)

    # ç­‰å¾…æ‰€æœ‰è§†é¢‘è¯»å–å®Œæˆ
    video_queue.join()

    # å‘é€ç»“æŸä¿¡å·ç»™è¯»å–çº¿ç¨‹
    for _ in range(NUM_READER_THREADS):
        video_queue.put(None)
    for t in reader_threads:
        t.join()

    # ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆ
    batch_queue.join()

    # å‘é€ç»“æŸä¿¡å·ç»™GPUçº¿ç¨‹
    batch_queue.put(None)
    gpu_thread.join()

    # ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ
    print("\nç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ...")
    write_queue.join()

    # å‘é€ç»“æŸä¿¡å·ç»™å†™å…¥çº¿ç¨‹
    for _ in range(NUM_IO_THREADS):
        write_queue.put(None)
    for t in write_threads:
        t.join()

    pbar.close()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'=' * 60}")
    print(f"âœ“ å¤„ç†å®Œæˆ!")
    print(f"{'=' * 60}")
    print(f"  - æˆåŠŸå¤„ç†è§†é¢‘æ•°: {stats['videos_read']}")
    print(f"  - å¤±è´¥è§†é¢‘æ•°: {stats['failed_videos']}")
    print(f"  - å¤„ç†æ‰¹æ¬¡æ•°: {stats['batches_processed']}")
    print(f"  - å¤„ç†å¸§æ•°: {stats['frames_processed']}")
    print(f"  - æå–äººè„¸æ•°: {stats['faces_detected']}")
    print(f"  - ç»“æœä¿å­˜åœ¨: {OUTPUT_ROOT}")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    process_videos()