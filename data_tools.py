import os
import random
import torch
from torch.utils.data import Dataset
from tqdm import tqdm
from PIL import Image
from torchvision import transforms
import torch
import random
import numpy as np
from typing import Optional, List, Tuple
from distortions import gaussian_blur, lens_blur, color_saturation, color_shift, jpeg, white_noise, impulse_noise, brighten, darken, jitter, quantization,linear_contrast_change

class DeepSpeakDataset(Dataset):
    """
    DeepSpeak ç»“æ„çš„ Dataset: root/{class}/{video_id}/{frame}.png

    - class: real / fake
    - video_id:
        - real: ä»»æ„å‘½åï¼ˆä¸å«ä¼ªé€ ç±»å‹ï¼‰
        - fake: å½¢å¦‚ diff2lip-7076-7066-speechify ï¼ˆç”¨ '-' åˆ†å‰²ï¼Œç¬¬ä¸€ä¸ªå­—æ®µæ˜¯ä¼ªé€ ç±»å‹ï¼‰
    - frame: *.png / *.jpg ...

    è¿”å›:
        img, real_fake_label, fake_type_str

    çº¦å®š:
        real_fake_label: real=1, fake=0
        fake_type_str: ä»… fake æœ‰æ„ä¹‰ï¼Œreal è¿”å› "real"ï¼ˆä½ ä¹Ÿå¯ä»¥æ”¹æˆ "none"ï¼‰
    """

    def __init__(self, root=None, max_videos=-1, max_frames=-1, logger=None, transform=None, augmentation=None, normalize=None):
        self.root = root
        self.transform = transform
        self.augmentation = augmentation
        self.normalize = normalize

        self.logger = logger

        if self.logger:
            self.logger.info(f"DeepSpeakDataset åˆå§‹åŒ–å®Œæˆï¼Œroot={root}")

        # samples: [(img_path, real_fake_label, fake_type_str), ...]
        self.samples = []

        # Real=1, Fake=0
        classes = {'real': 1, 'fake': 0}
        valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')

        self.logger.info(f"æ­£åœ¨æ„å»º DeepSpeak æ•°æ®é›†ç´¢å¼•: {root}")
        self.logger.info(f"  é‡‡æ ·è®¾ç½®: max_videos={max_videos}, max_frames={max_frames}")

        for cls_name, cls_label in classes.items():
            cls_folder = os.path.join(root, cls_name)
            if not os.path.isdir(cls_folder):
                self.logger.info(f"  è­¦å‘Š: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹ {cls_folder}")
                continue

            # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶å¤¹
            video_folders = [
                d for d in os.listdir(cls_folder)
                if os.path.isdir(os.path.join(cls_folder, d))
            ]
            video_folders.sort()

            # 1) è§†é¢‘çº§é‡‡æ ·
            if max_videos > 0 and len(video_folders) > max_videos:
                rng = random.Random(42)
                selected_videos = rng.sample(video_folders, max_videos)
            else:
                selected_videos = video_folders

            self.logger.info(f"  ç±»åˆ« '{cls_name}': æ‰«æäº† {len(selected_videos)}/{len(video_folders)} ä¸ªè§†é¢‘æ–‡ä»¶å¤¹...")

            count_imgs = 0
            for vid in tqdm(selected_videos, desc=f"Scanning {cls_name}", leave=False):
                vid_path = os.path.join(cls_folder, vid)

                # 2) è§£æ fake_typeï¼ˆä»… fake æœ‰ï¼‰
                if cls_name == "fake":
                    # diff2lip-7076-7066-speechify -> diff2lip
                    fake_type = vid.split('-')[0].strip()
                    if fake_type == "":
                        fake_type = "unknown"
                    fake_type_str = fake_type
                else:
                    fake_type_str = "real"  # æˆ–è€…æ”¹æˆ "none"

                # è·å–æ‰€æœ‰å›¾ç‰‡å¸§
                images = [f for f in os.listdir(vid_path) if f.lower().endswith(valid_extensions)]
                images.sort()

                # 3) å¸§çº§é‡‡æ ·
                if max_frames > 0 and len(images) > max_frames:
                    rng = random.Random(42)
                    selected_images = rng.sample(images, max_frames)
                else:
                    selected_images = images

                for img_name in selected_images:
                    img_path = os.path.join(vid_path, img_name)
                    self.samples.append((img_path, cls_label, fake_type_str))
                    count_imgs += 1

            self.logger.info(f"  ç±»åˆ« '{cls_name}': å…±åŠ è½½ {count_imgs} å¼ å›¾åƒã€‚")

        # æ‰“å°ä¸€ä¸‹å‘ç°çš„ fake_typeï¼ˆå¯é€‰ï¼‰
        fake_types = sorted({ft for _, y, ft in self.samples if y == 0})
        if len(fake_types) > 0:
            self.logger.info(f"[ç»Ÿè®¡] å…±å‘ç° {len(fake_types)} ç§ä¼ªé€ ç±»å‹: {fake_types}")
        else:
            self.logger.info("[ç»Ÿè®¡] æœªå‘ç°ä¼ªé€ ç±»å‹ï¼ˆå¯èƒ½æ²¡æœ‰ fake ç±»åˆ«æˆ– fake æ–‡ä»¶å¤¹ä¸ºç©ºï¼‰ã€‚")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, index):
        path, label, fake_type_str = self.samples[index]
        img = Image.open(path).convert('RGB')

        # 1. Resize, Crop, ToTensor
        if self.transform:
            img = self.transform(img)

        # 2. Augmentation (åœ¨ [0,1] ä¸Š)
        if self.augmentation:
            img = self.augmentation(img, label)

        # 3. Normalize
        if self.normalize:
            img = self.normalize(img)

        return img, label, fake_type_str, path

class FFPPDataset(Dataset):
    """
    FaceForensics++ (FF++) æ•°æ®é›†åŠ è½½å™¨

    æ•°æ®é›†ç»“æ„:
        root/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ Deepfakes/
        â”‚   â”œâ”€â”€ Face2Face/
        â”‚   â”œâ”€â”€ FaceShifter/
        â”‚   â”œâ”€â”€ FaceSwap/
        â”‚   â”œâ”€â”€ NeuralTextures/
        â”‚   â””â”€â”€ original/
        â”œâ”€â”€ test/
        â””â”€â”€ val/

    æ¯ä¸ªç±»å‹æ–‡ä»¶å¤¹ä¸‹åŒ…å«è§†é¢‘æ–‡ä»¶å¤¹(å¦‚ 001_870/)ï¼Œè§†é¢‘æ–‡ä»¶å¤¹å†…æ˜¯å¸§å›¾ç‰‡(*.png)

    å‚æ•°:
        root (str): æ•°æ®é›†æ ¹ç›®å½•
        split (str): 'train', 'test' æˆ– 'val'
        fake_types (list): è¦ä½¿ç”¨çš„ä¼ªé€ ç±»å‹åˆ—è¡¨ï¼Œå¦‚ ['Deepfakes', 'Face2Face']
        transform: å›¾åƒå˜æ¢
        max_videos (int): æ¯ä¸ªç±»å‹æœ€å¤šé‡‡æ ·çš„è§†é¢‘æ•°ï¼Œ-1è¡¨ç¤ºå…¨éƒ¨
        max_frames (int): æ¯ä¸ªè§†é¢‘æœ€å¤šé‡‡æ ·çš„å¸§æ•°ï¼Œ-1è¡¨ç¤ºå…¨éƒ¨

    è¿”å›:
        img: å›¾åƒå¼ é‡
        real_fake_label: 1=real, 0=fake
        fake_type_str: ä¼ªé€ ç±»å‹åç§°æˆ–'original'
        path: å›¾åƒè·¯å¾„

    çœŸä¼ªå¹³è¡¡ç­–ç•¥:
        - æ¯ç§fakeç±»å‹é‡‡æ · max_videos ä¸ªè§†é¢‘ï¼ˆ-1è¡¨ç¤ºå…¨éƒ¨ï¼‰
        - original å…ˆé‡‡æ · max_videos ä¸ªè§†é¢‘ï¼Œç„¶åå°†è§†é¢‘åˆ—è¡¨é‡å¤ len(fake_types) å€
        - ä¾‹å¦‚ï¼šmax_videos=100, fake_types=['A','B']
          â†’ æ¯ç§fakeé‡‡æ ·100ä¸ªè§†é¢‘
          â†’ originalé‡‡æ ·100ä¸ªè§†é¢‘ï¼Œé‡å¤2å€å¾—åˆ°200ä¸ªè§†é¢‘IDï¼ˆæœ‰é‡å¤ï¼‰
          â†’ æœ€ç»ˆæ¯ä¸ªoriginalè§†é¢‘çš„å¸§ä¼šè¢«ä½¿ç”¨2æ¬¡
    """

    def __init__(self, root, split='train', fake_types=None, max_videos=-1, max_frames=-1, logger=None, transform=None, augmentation=None, normalize=None):
        self.root = root
        self.split = split
        self.fake_types = fake_types
        self.transform = transform
        self.augmentation = augmentation
        self.normalize = normalize


        self.max_videos = max_videos
        self.max_frames = max_frames
        self.logger = logger
        if self.logger:
            self.logger.info(f"FFPPDataset åˆå§‹åŒ–å®Œæˆï¼Œroot={root}")

        # samples: [(img_path, real_fake_label, fake_type_str), ...]
        self.samples = []

        # æœ‰æ•ˆå›¾åƒæ‰©å±•å
        self.valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')

        # æ•°æ®é›†åˆ†å‰²ç›®å½•
        self.split_dir = os.path.join(root, split)
        if not os.path.isdir(self.split_dir):
            raise ValueError(f"åˆ†å‰²ç›®å½•ä¸å­˜åœ¨: {self.split_dir}")

        self.logger.info(f"\n{'=' * 60}")
        self.logger.info(f"æ­£åœ¨æ„å»º FF++ æ•°æ®é›†: {split} split")
        self.logger.info(f"  æ ¹ç›®å½•: {root}")
        self.logger.info(f"  ä½¿ç”¨çš„ä¼ªé€ ç±»å‹: {fake_types} (å…± {len(fake_types)} ç§)")
        self.logger.info(f"  é‡‡æ ·è®¾ç½®: max_videos={max_videos}, max_frames={max_frames}")
        self.logger.info(f"  çœŸä¼ªå¹³è¡¡: original è§†é¢‘åˆ—è¡¨é‡å¤ {len(fake_types)} å€")
        self.logger.info(f"{'=' * 60}\n")

        # 1. å…ˆå¤„ç†æ‰€æœ‰fakeç±»å‹
        for fake_type in fake_types:
            self._load_class(fake_type, label=0)

        # 2. å†å¤„ç†original (å¹³è¡¡é‡‡æ · - é‡å¤è§†é¢‘åˆ—è¡¨)
        self._load_original_balanced()

        # ç»Ÿè®¡ä¿¡æ¯
        self._print_statistics()

    def _load_original_balanced(self):
        """
        åŠ è½½ original ç±»åˆ«ï¼Œå¹¶é€šè¿‡é‡å¤è§†é¢‘åˆ—è¡¨å®ç°å¹³è¡¡é‡‡æ ·

        é€»è¾‘ï¼š
        1. è¯»å– original æ–‡ä»¶å¤¹æ‰€æœ‰è§†é¢‘
        2. æŒ‰ max_videos é‡‡æ ·ï¼ˆå¦‚æœ max_videos > 0ï¼‰
        3. å°†é‡‡æ ·åçš„è§†é¢‘åˆ—è¡¨é‡å¤ len(fake_types) å€
        4. ä»é‡å¤åçš„åˆ—è¡¨ä¸­åŠ è½½æ‰€æœ‰å¸§
        """
        class_name = 'original'
        class_folder = os.path.join(self.split_dir, class_name)

        if not os.path.isdir(class_folder):
            self.logger.info(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹ {class_folder}")
            return

        # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶å¤¹
        video_folders = [
            d for d in os.listdir(class_folder)
            if os.path.isdir(os.path.join(class_folder, d))
        ]
        video_folders.sort()

        total_videos = len(video_folders)

        # è§†é¢‘çº§é‡‡æ ·
        if self.max_videos > 0 and total_videos > self.max_videos:
            rng = random.Random(42)
            selected_videos = rng.sample(video_folders, self.max_videos)
        else:
            selected_videos = video_folders

        # é‡å¤è§†é¢‘åˆ—è¡¨ len(fake_types) å€
        repeated_videos = selected_videos * len(self.fake_types)

        self.logger.info(f"  ğŸ“ ç±»åˆ« '{class_name}': åŸå§‹ {len(selected_videos)}/{total_videos} ä¸ªè§†é¢‘")
        self.logger.info(f"     â†’ é‡å¤ {len(self.fake_types)} å€åå…± {len(repeated_videos)} ä¸ªè§†é¢‘ï¼ˆç”¨äºå¹³è¡¡é‡‡æ ·ï¼‰...")

        label = 1  # real
        fake_type_str = 'original'

        count_imgs = 0
        for vid in tqdm(repeated_videos, desc=f"  Loading {class_name}", leave=False):
            vid_path = os.path.join(class_folder, vid)

            # è·å–æ‰€æœ‰å›¾ç‰‡å¸§
            images = [
                f for f in os.listdir(vid_path)
                if f.lower().endswith(self.valid_extensions)
            ]
            images.sort()

            if len(images) == 0:
                continue

            # å¸§çº§é‡‡æ ·
            if self.max_frames > 0 and len(images) > self.max_frames:
                rng = random.Random(42)
                selected_images = rng.sample(images, self.max_frames)
            else:
                selected_images = images

            for img_name in selected_images:
                img_path = os.path.join(vid_path, img_name)
                self.samples.append((img_path, label, fake_type_str))
                count_imgs += 1

        self.logger.info(f"  âœ“  ç±»åˆ« '{class_name}': å…±åŠ è½½ {count_imgs} å¼ å›¾åƒ\n")

    def _load_class(self, class_name, label):
        """
        åŠ è½½æŸä¸ªç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬

        Args:
            class_name: ç±»åˆ«åç§° (å¦‚ 'Deepfakes')
            label: 0=fake, 1=real
        """
        class_folder = os.path.join(self.split_dir, class_name)

        if not os.path.isdir(class_folder):
            self.logger.info(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹ {class_folder}")
            return

        # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶å¤¹
        video_folders = [
            d for d in os.listdir(class_folder)
            if os.path.isdir(os.path.join(class_folder, d))
        ]
        video_folders.sort()

        total_videos = len(video_folders)

        # è§†é¢‘çº§é‡‡æ ·
        if self.max_videos > 0 and total_videos > self.max_videos:
            rng = random.Random(42)
            selected_videos = rng.sample(video_folders, self.max_videos)
        else:
            selected_videos = video_folders

        self.logger.info(f"  ğŸ“ ç±»åˆ« '{class_name}': æ‰«æ {len(selected_videos)}/{total_videos} ä¸ªè§†é¢‘æ–‡ä»¶å¤¹...")

        # fake_type_str: å¯¹äºfakeä½¿ç”¨ç±»åˆ«åï¼Œå¯¹äºrealä½¿ç”¨'original'
        fake_type_str = class_name

        count_imgs = 0
        for vid in tqdm(selected_videos, desc=f"  Loading {class_name}", leave=False):
            vid_path = os.path.join(class_folder, vid)

            # è·å–æ‰€æœ‰å›¾ç‰‡å¸§
            images = [
                f for f in os.listdir(vid_path)
                if f.lower().endswith(self.valid_extensions)
            ]
            images.sort()

            if len(images) == 0:
                continue

            # å¸§çº§é‡‡æ ·
            if self.max_frames > 0 and len(images) > self.max_frames:
                rng = random.Random(42)
                selected_images = rng.sample(images, self.max_frames)
            else:
                selected_images = images

            for img_name in selected_images:
                img_path = os.path.join(vid_path, img_name)
                self.samples.append((img_path, label, fake_type_str))
                count_imgs += 1

        self.logger.info(f"  âœ“  ç±»åˆ« '{class_name}': å…±åŠ è½½ {count_imgs} å¼ å›¾åƒ\n")

    def _print_statistics(self):
        """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info(f"\n{'=' * 60}")
        self.logger.info(f"æ•°æ®é›†æ„å»ºå®Œæˆ!")
        self.logger.info(f"{'=' * 60}")

        # ç»Ÿè®¡real/fakeæ•°é‡
        real_count = sum(1 for _, label, _ in self.samples if label == 1)
        fake_count = sum(1 for _, label, _ in self.samples if label == 0)

        self.logger.info(f"  æ€»æ ·æœ¬æ•°: {len(self.samples)}")
        self.logger.info(f"  Realæ ·æœ¬: {real_count} ({real_count / len(self.samples) * 100:.1f}%)")
        self.logger.info(f"  Fakeæ ·æœ¬: {fake_count} ({fake_count / len(self.samples) * 100:.1f}%)")

        # ç»Ÿè®¡å„ä¼ªé€ ç±»å‹æ•°é‡
        fake_type_counts = {}
        for _, label, fake_type in self.samples:
            if fake_type not in fake_type_counts:
                fake_type_counts[fake_type] = 0
            fake_type_counts[fake_type] += 1

        self.logger.info(f"\n  å„ç±»å‹åˆ†å¸ƒ:")
        for ft in sorted(fake_type_counts.keys()):
            count = fake_type_counts[ft]
            self.logger.info(f"    - {ft:20s}: {count:6d} ({count / len(self.samples) * 100:.1f}%)")

        self.logger.info(f"{'=' * 60}\n")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, index):
        path, label, fake_type_str = self.samples[index]
        img = Image.open(path).convert('RGB')

        # 1. Resize, Crop, ToTensor
        if self.transform:
            img = self.transform(img)

        # 2. Augmentation (åœ¨ [0,1] ä¸Š)
        if self.augmentation:
            img = self.augmentation(img, label)

        # 3. Normalize
        if self.normalize:
            img = self.normalize(img)

        return img, label, fake_type_str, path

class ConditionalResize(object):
    """
    (æ¥è‡ª eval_UniversalFakeDetect.py)
    å¯åºåˆ—åŒ–çš„è½¬æ¢
    """

    def __init__(self, size):
        self.size = size
        self.resize_op = transforms.Resize(size)

    def __call__(self, img):
        if min(img.size) < self.size:
            return self.resize_op(img)
        return img


def get_transforms(args):
    model_name = args.model_name.lower()

    if "clip" in model_name:
        # CLIP å®˜æ–¹å½’ä¸€åŒ–
        mean = [0.48145466, 0.4578275, 0.40821073]
        std  = [0.26862954, 0.26130258, 0.27577711]
    else:

        mean = [0.5, 0.5, 0.5]
        std  = [0.5, 0.5, 0.5]

    transform_list = [
        ConditionalResize(args.img_size),
        transforms.RandomCrop(args.img_size),
        transforms.ToTensor(),
    ]

    return transforms.Compose(transform_list), transforms.Normalize(mean=mean, std=std)


def get_dataset_type(data_root):
    """æ ¹æ®è·¯å¾„è‡ªåŠ¨è¯†åˆ«æ•°æ®é›†ç±»å‹"""
    data_root_lower = data_root.lower()
    if 'deepspeak' in data_root_lower:
        return 'DeepSpeak'
    elif 'faceforensics' in data_root_lower or 'ff++' in data_root_lower or 'ffpp' in data_root_lower:
        return 'FFPP'
    else:
        # é»˜è®¤æˆ–æ ¹æ®å…¶ä»–è§„åˆ™åˆ¤æ–­
        raise ValueError(f"æ— æ³•ä»è·¯å¾„è¯†åˆ«æ•°æ®é›†ç±»å‹: {data_root}")


def create_dataset(data_root, max_videos, max_frames, args, logger, transform, normalize, augmentation=None):
    """
    æ ¹æ®data_rootè‡ªåŠ¨è¯†åˆ«å¹¶åˆ›å»ºå¯¹åº”çš„æ•°æ®é›†
    """
    dataset_type = get_dataset_type(data_root)

    if dataset_type == 'FFPP':
        return FFPPDataset(
            root=data_root,
            split=args.ff_split,
            fake_types=args.fake_types,
            max_videos=max_videos,
            max_frames=max_frames,
            logger=logger,
            transform=transform,
            augmentation=augmentation,
            normalize=normalize,
        )
    elif dataset_type == 'DeepSpeak':
        return DeepSpeakDataset(
            root=data_root,
            max_videos=max_videos,
            max_frames=max_frames,
            logger=logger,
            transform=transform,
            augmentation=augmentation,
            normalize=normalize,
        )
    else:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†ç±»å‹: {dataset_type}")
